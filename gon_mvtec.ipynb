{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR 1001 EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'V:\\\\Dataset\\\\ACV\\\\mvtec_anomaly_detection'\n",
    "\n",
    "# Dataset loading\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, base_dir, data_type, transform=None):\n",
    "        self.base_dir = base_dir\n",
    "        self.data_type = data_type\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "        self.targets = []\n",
    "        self.normal_count = 0\n",
    "        self.anomaly_count = 0\n",
    "\n",
    "        for category in os.listdir(base_dir):\n",
    "            category_path = os.path.join(base_dir, category)\n",
    "            if os.path.isdir(category_path):\n",
    "                type_path = os.path.join(category_path, data_type)\n",
    "                if os.path.isdir(type_path):\n",
    "                    for defect_class in os.listdir(type_path):\n",
    "                        defect_class_path = os.path.join(type_path, defect_class)\n",
    "                        if os.path.isdir(defect_class_path):\n",
    "                            for img_file in os.listdir(defect_class_path):\n",
    "                                img_file_path = os.path.join(defect_class_path, img_file)\n",
    "                                if img_file.lower().endswith(('png', 'jpg', 'jpeg')):\n",
    "                                    self.image_files.append(img_file_path)\n",
    "                                    if data_type == 'train' or defect_class.lower() == 'good':\n",
    "                                        self.targets.append(0)  \n",
    "                                        self.normal_count += 1\n",
    "                                    else:\n",
    "                                        self.targets.append(1)  \n",
    "                                        self.anomaly_count += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_files[index]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        label = self.targets[index]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "img_transform = T.Compose([\n",
    "    T.Resize((64, 64)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Loading datasets\n",
    "train_data = MyDataset(data_dir, 'train', transform=img_transform)\n",
    "test_data = MyDataset(data_dir, 'test', transform=img_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=64, drop_last=True)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=64, drop_last=True)\n",
    "\n",
    "print(f\"Training images: {len(train_data)}\")\n",
    "print(f\"  Normal in training set: {train_data.normal_count}\")\n",
    "print(f\"Testing images: {len(test_data)}\")\n",
    "print(f\"  Normal in test set: {test_data.normal_count}\")\n",
    "print(f\"  Anomalous in test set: {test_data.anomaly_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle(loader):\n",
    "    while True:\n",
    "        for data in loader:\n",
    "            yield data\n",
    "\n",
    "train_iter = iter(cycle(train_loader))\n",
    "\n",
    "# Parameters Initialization\n",
    "latent_size = 100  \n",
    "gen_filter_size = 124  \n",
    "learning_rate = 1e-4\n",
    "training_steps = 1001 \n",
    "batch_sz = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Training on {'GPU' if torch.cuda.is_available() else 'CPU'}.\")\n",
    "\n",
    "class GenModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GenModel, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_size, gen_filter_size * 8, 4, 1, 0, bias=True),\n",
    "            nn.BatchNorm2d(gen_filter_size * 8),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(gen_filter_size * 8, gen_filter_size * 4, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(gen_filter_size * 4),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(gen_filter_size * 4, gen_filter_size * 2, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(gen_filter_size * 2),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(gen_filter_size * 2, gen_filter_size, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(gen_filter_size),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(gen_filter_size, 3, 4, 2, 1, bias=True),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Initializing model and optimizer\n",
    "gen_model = GenModel().to(device)\n",
    "gen_optimizer = optim.Adam(gen_model.parameters(), lr=learning_rate)\n",
    "print(f'> Model parameters: {sum(p.numel() for p in gen_model.parameters() if p.requires_grad)}')\n",
    "\n",
    "def slerp(interpol, a, b):\n",
    "    omega = torch.acos((a / torch.norm(a, dim=1, keepdim=True) * b / torch.norm(b, dim=1, keepdim=True)).sum(1)).unsqueeze(1)\n",
    "    result = (torch.sin((1.0 - interpol) * omega) / torch.sin(omega)) * a + (torch.sin(interpol * omega) / torch.sin(omega)) * b\n",
    "    return result\n",
    "\n",
    "def slerp_gen_batch(gen, z):\n",
    "    lz = z.data.clone().squeeze(-1).squeeze(-1)\n",
    "    col_size = int(np.sqrt(z.size(0)))\n",
    "    src_z = lz.data[:col_size].repeat(col_size, 1)\n",
    "    z1, z2 = lz.data.split(lz.shape[0] // 2)\n",
    "    tgt_z = torch.cat([z2, z1])\n",
    "    tgt_z = tgt_z[:col_size].repeat(col_size, 1)\n",
    "    t = torch.linspace(0, 1, col_size).unsqueeze(1).repeat(1, col_size).contiguous().view(batch_sz, 1).contiguous().to(device)\n",
    "    z_slerp = slerp(t, src_z, tgt_z)\n",
    "    g_slerp = gen(z_slerp.unsqueeze(-1).unsqueeze(-1))\n",
    "    return g_slerp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "train_losses = []\n",
    "for step in tqdm(range(training_steps)):\n",
    "    x, _ = next(train_iter)\n",
    "    x = x.to(device)\n",
    "\n",
    "    # Calculation of inner loss gradients with respect to zeros\n",
    "    z = torch.zeros(batch_sz, latent_size, 1, 1, device=device, requires_grad=True)\n",
    "    g = gen_model(z)\n",
    "    inner_loss = ((g - x) ** 2).sum(1).mean()\n",
    "    grad = torch.autograd.grad(inner_loss, [z], create_graph=True, retain_graph=True)[0]\n",
    "    z = (-grad)\n",
    "\n",
    "    # Optimizing the data fitting loss with new latent points\n",
    "    g = gen_model(z)\n",
    "    outer_loss = ((g - x) ** 2).sum(1).mean()\n",
    "    gen_optimizer.zero_grad()\n",
    "    outer_loss.backward()\n",
    "    gen_optimizer.step()\n",
    "\n",
    "    train_losses.append(outer_loss.item())\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step: {step}   Loss: {outer_loss.item():.3f}\")\n",
    "\n",
    "        reconstructions = torchvision.utils.make_grid(torch.clamp(g, 0, 1).detach(), padding=0, nrow=8)\n",
    "        slerp_interpolations = torchvision.utils.make_grid(torch.clamp(slerp_gen_batch(gen_model, z.data).detach(), 0, 1), padding=0, nrow=8)\n",
    "        true_images = torchvision.utils.make_grid(torch.clamp(x, 0, 1).detach(), padding=0, nrow=8)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.title('True Images')\n",
    "        plt.imshow(np.transpose(true_images.cpu().numpy(), (1, 2, 0)))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.title('Reconstructed Images')\n",
    "        plt.imshow(np.transpose(reconstructions.cpu().numpy(), (1, 2, 0)))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.title('Spherical Interpolations')\n",
    "        plt.imshow(np.transpose(slerp_interpolations.cpu().numpy(), (1, 2, 0)))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomoly Detection calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic threshold calculation\n",
    "def dynamic_threshold(loss_vals):\n",
    "    mean_loss = np.mean(loss_vals)\n",
    "    std_loss = np.std(loss_vals)\n",
    "    return mean_loss + 2 * std_loss  \n",
    "\n",
    "initial_threshold = dynamic_threshold(train_losses)\n",
    "print(f\"Initial anomaly detection threshold: {initial_threshold}\")\n",
    "\n",
    "# Computation of reconstruction errors\n",
    "def reconstruction_errors(gen_model, data_loader):\n",
    "    gen_model.eval()\n",
    "    errors = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            imgs = imgs.to(device)\n",
    "            z = torch.zeros(imgs.size(0), latent_size, 1, 1, device=device)\n",
    "            gen_imgs = gen_model(z)\n",
    "            loss = torch.mean((gen_imgs - imgs) ** 2, dim=[1, 2, 3])\n",
    "            errors.extend(loss.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    return np.array(errors), np.array(true_labels)\n",
    "\n",
    "recon_errors, true_lbls = reconstruction_errors(gen_model, test_loader)\n",
    "\n",
    "assert recon_errors.shape == true_lbls.shape, \"Shape mismatch between errors and true labels.\"\n",
    "\n",
    "# Anomaly detection using the threshold\n",
    "anomalies_detected = recon_errors > initial_threshold\n",
    "print(f\"Detected anomalies: {np.sum(anomalies_detected)}\")\n",
    "\n",
    "true_labels_list = []\n",
    "pred_labels_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(test_loader, desc=\"Anomaly Detection\"):\n",
    "        imgs = imgs.to(device)\n",
    "        z = torch.zeros(imgs.size(0), latent_size, 1, 1, device=device)\n",
    "        gen_imgs = gen_model(z)\n",
    "        recon_error = torch.mean((gen_imgs - imgs) ** 2, dim=[1, 2, 3]).cpu().numpy()\n",
    "        true_labels_list.extend(labels.cpu().numpy())\n",
    "        pred_labels_list.extend([1 if e > initial_threshold else 0 for e in recon_error])\n",
    "\n",
    "print(f\"Anomalies detected in the test set: {np.sum(anomalies_detected)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction error distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Reconstruction Error Distribution')\n",
    "sns.histplot(recon_errors, bins=100, kde=True, color='blue')\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Reconstructed images\n",
    "z = torch.zeros(imgs.size(0), latent_size, 1, 1, device=device)\n",
    "with torch.no_grad():\n",
    "    gen_imgs = gen_model(z)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Reconstructed Images')\n",
    "plt.imshow(np.transpose(torchvision.utils.make_grid(gen_imgs.cpu().detach(), padding=2, normalize=True), (1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Training loss\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title('Training Loss')\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# Loss distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Loss Distribution')\n",
    "sns.histplot(recon_errors, bins=100, kde=True, color='blue')\n",
    "plt.axvline(initial_threshold, color='r')\n",
    "plt.axvline(0.0, color='b')\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels_list, pred_labels_list)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix for Anomaly Detection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  FOR 3001 EPOCHS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'V:\\\\Dataset\\\\ACV\\\\mvtec_anomaly_detection'\n",
    "\n",
    "# Dataset  loading \n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, base_dir, data_type, transform=None):\n",
    "        self.base_dir = base_dir\n",
    "        self.data_type = data_type\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "        self.targets = []\n",
    "        self.normal_count = 0\n",
    "        self.anomaly_count = 0\n",
    "\n",
    "        for category in os.listdir(base_dir):\n",
    "            category_path = os.path.join(base_dir, category)\n",
    "            if os.path.isdir(category_path):\n",
    "                type_path = os.path.join(category_path, data_type)\n",
    "                if os.path.isdir(type_path):\n",
    "                    for defect_class in os.listdir(type_path):\n",
    "                        defect_class_path = os.path.join(type_path, defect_class)\n",
    "                        if os.path.isdir(defect_class_path):\n",
    "                            for img_file in os.listdir(defect_class_path):\n",
    "                                img_file_path = os.path.join(defect_class_path, img_file)\n",
    "                                if img_file.lower().endswith(('png', 'jpg', 'jpeg')):\n",
    "                                    self.image_files.append(img_file_path)\n",
    "                                    if data_type == 'train' or defect_class.lower() == 'good':\n",
    "                                        self.targets.append(0)  \n",
    "                                        self.normal_count += 1\n",
    "                                    else:\n",
    "                                        self.targets.append(1)  \n",
    "                                        self.anomaly_count += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_files[index]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        label = self.targets[index]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "img_transform = T.Compose([\n",
    "    T.Resize((64, 64)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Loading datasets\n",
    "train_data = MyDataset(data_dir, 'train', transform=img_transform)\n",
    "test_data = MyDataset(data_dir, 'test', transform=img_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=64, drop_last=True)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=64, drop_last=True)\n",
    "\n",
    "print(f\"Training images: {len(train_data)}\")\n",
    "print(f\"  Normal in training set: {train_data.normal_count}\")\n",
    "print(f\"Testing images: {len(test_data)}\")\n",
    "print(f\"  Normal in test set: {test_data.normal_count}\")\n",
    "print(f\"  Anomalous in test set: {test_data.anomaly_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle(loader):\n",
    "    while True:\n",
    "        for data in loader:\n",
    "            yield data\n",
    "\n",
    "train_iter = iter(cycle(train_loader))\n",
    "\n",
    "# Parameters Initialization\n",
    "latent_size = 100  \n",
    "gen_filter_size = 124  \n",
    "learning_rate = 1e-4\n",
    "training_steps = 3001  \n",
    "batch_sz = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Training on {'GPU' if torch.cuda.is_available() else 'CPU'}.\")\n",
    "\n",
    "class GenModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GenModel, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_size, gen_filter_size * 8, 4, 1, 0, bias=True),\n",
    "            nn.BatchNorm2d(gen_filter_size * 8),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(gen_filter_size * 8, gen_filter_size * 4, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(gen_filter_size * 4),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(gen_filter_size * 4, gen_filter_size * 2, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(gen_filter_size * 2),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(gen_filter_size * 2, gen_filter_size, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(gen_filter_size),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(gen_filter_size, 3, 4, 2, 1, bias=True),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Initializing model and optimizer\n",
    "gen_model = GenModel().to(device)\n",
    "gen_optimizer = optim.Adam(gen_model.parameters(), lr=learning_rate)\n",
    "print(f'> Model parameters: {sum(p.numel() for p in gen_model.parameters() if p.requires_grad)}')\n",
    "\n",
    "def slerp(interpol, a, b):\n",
    "    omega = torch.acos((a / torch.norm(a, dim=1, keepdim=True) * b / torch.norm(b, dim=1, keepdim=True)).sum(1)).unsqueeze(1)\n",
    "    result = (torch.sin((1.0 - interpol) * omega) / torch.sin(omega)) * a + (torch.sin(interpol * omega) / torch.sin(omega)) * b\n",
    "    return result\n",
    "\n",
    "def slerp_gen_batch(gen, z):\n",
    "    lz = z.data.clone().squeeze(-1).squeeze(-1)\n",
    "    col_size = int(np.sqrt(z.size(0)))\n",
    "    src_z = lz.data[:col_size].repeat(col_size, 1)\n",
    "    z1, z2 = lz.data.split(lz.shape[0] // 2)\n",
    "    tgt_z = torch.cat([z2, z1])\n",
    "    tgt_z = tgt_z[:col_size].repeat(col_size, 1)\n",
    "    t = torch.linspace(0, 1, col_size).unsqueeze(1).repeat(1, col_size).contiguous().view(batch_sz, 1).contiguous().to(device)\n",
    "    z_slerp = slerp(t, src_z, tgt_z)\n",
    "    g_slerp = gen(z_slerp.unsqueeze(-1).unsqueeze(-1))\n",
    "    return g_slerp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "train_losses = []\n",
    "for step in tqdm(range(training_steps)):\n",
    "    x, _ = next(train_iter)\n",
    "    x = x.to(device)\n",
    "\n",
    "    # Calculation of inner loss gradients with respect to zeros\n",
    "    z = torch.zeros(batch_sz, latent_size, 1, 1, device=device, requires_grad=True)\n",
    "    g = gen_model(z)\n",
    "    inner_loss = ((g - x) ** 2).sum(1).mean()\n",
    "    grad = torch.autograd.grad(inner_loss, [z], create_graph=True, retain_graph=True)[0]\n",
    "    z = (-grad)\n",
    "\n",
    "    # Optimization the data fitting loss with new latent points\n",
    "    g = gen_model(z)\n",
    "    outer_loss = ((g - x) ** 2).sum(1).mean()\n",
    "    gen_optimizer.zero_grad()\n",
    "    outer_loss.backward()\n",
    "    gen_optimizer.step()\n",
    "\n",
    "    train_losses.append(outer_loss.item())\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step: {step}   Loss: {outer_loss.item():.3f}\")\n",
    "\n",
    "        reconstructions = torchvision.utils.make_grid(torch.clamp(g, 0, 1).detach(), padding=0, nrow=8)\n",
    "        slerp_interpolations = torchvision.utils.make_grid(torch.clamp(slerp_gen_batch(gen_model, z.data).detach(), 0, 1), padding=0, nrow=8)\n",
    "        true_images = torchvision.utils.make_grid(torch.clamp(x, 0, 1).detach(), padding=0, nrow=8)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.title('True Images')\n",
    "        plt.imshow(np.transpose(true_images.cpu().numpy(), (1, 2, 0)))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.title('Reconstructed Images')\n",
    "        plt.imshow(np.transpose(reconstructions.cpu().numpy(), (1, 2, 0)))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.title('Spherical Interpolations')\n",
    "        plt.imshow(np.transpose(slerp_interpolations.cpu().numpy(), (1, 2, 0)))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomoly Detection calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic threshold calculation\n",
    "def dynamic_threshold(loss_vals):\n",
    "    mean_loss = np.mean(loss_vals)\n",
    "    std_loss = np.std(loss_vals)\n",
    "    return mean_loss + 2 * std_loss  \n",
    "\n",
    "# Initialization of anomaly detection threshold\n",
    "initial_threshold = dynamic_threshold(train_losses)\n",
    "print(f\"Initial anomaly detection threshold: {initial_threshold}\")\n",
    "\n",
    "# Computation of reconstruction errors\n",
    "def reconstruction_errors(gen_model, data_loader):\n",
    "    gen_model.eval()\n",
    "    errors = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            imgs = imgs.to(device)\n",
    "            z = torch.zeros(imgs.size(0), latent_size, 1, 1, device=device)\n",
    "            gen_imgs = gen_model(z)\n",
    "            loss = torch.mean((gen_imgs - imgs) ** 2, dim=[1, 2, 3])\n",
    "            errors.extend(loss.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    return np.array(errors), np.array(true_labels)\n",
    "\n",
    "recon_errors, true_lbls = reconstruction_errors(gen_model, test_loader)\n",
    "\n",
    "assert recon_errors.shape == true_lbls.shape, \"Shape mismatch between errors and true labels.\"\n",
    "\n",
    "# Anomaly detection using the threshold\n",
    "anomalies_detected = recon_errors > initial_threshold\n",
    "print(f\"Detected anomalies: {np.sum(anomalies_detected)}\")\n",
    "\n",
    "# Anomaly detection on test data\n",
    "true_labels_list = []\n",
    "pred_labels_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(test_loader, desc=\"Anomaly Detection\"):\n",
    "        imgs = imgs.to(device)\n",
    "        z = torch.zeros(imgs.size(0), latent_size, 1, 1, device=device)\n",
    "        gen_imgs = gen_model(z)\n",
    "        recon_error = torch.mean((gen_imgs - imgs) ** 2, dim=[1, 2, 3]).cpu().numpy()\n",
    "        true_labels_list.extend(labels.cpu().numpy())\n",
    "        pred_labels_list.extend([1 if e > initial_threshold else 0 for e in recon_error])\n",
    "\n",
    "print(f\"Anomalies detected in the test set: {np.sum(anomalies_detected)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction error distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Reconstruction Error Distribution')\n",
    "sns.histplot(recon_errors, bins=100, kde=True, color='blue')\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Reconstructed images\n",
    "z = torch.zeros(imgs.size(0), latent_size, 1, 1, device=device)\n",
    "with torch.no_grad():\n",
    "    gen_imgs = gen_model(z)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Reconstructed Images')\n",
    "plt.imshow(np.transpose(torchvision.utils.make_grid(gen_imgs.cpu().detach(), padding=2, normalize=True), (1, 2, 0)))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Training loss\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title('Training Loss')\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# Loss distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Loss Distribution')\n",
    "sns.histplot(recon_errors, bins=100, kde=True, color='blue')\n",
    "plt.axvline(initial_threshold, color='r')\n",
    "plt.axvline(0.0, color='b')\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels_list, pred_labels_list)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix for Anomaly Detection')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Seminar_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
